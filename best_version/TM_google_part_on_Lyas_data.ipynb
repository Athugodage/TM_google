{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef76628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in c:\\conda\\lib\\site-packages (0.9.1)\n",
      "Requirement already satisfied: docopt>=0.6 in c:\\conda\\lib\\site-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in c:\\conda\\lib\\site-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in c:\\conda\\lib\\site-packages (from pymorphy2) (2.4.417127.4579844)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\conda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\conda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\conda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\conda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\conda\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\conda\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15b05196",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait as Wait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import csv\n",
    "\n",
    "import requests\n",
    "\n",
    "from lxml import html\n",
    "\n",
    "import re\n",
    "\n",
    "import unicodedata\n",
    "\n",
    "import pymorphy2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16b2c7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lyasdata.txt', 'r', encoding='utf8') as f:\n",
    "    f = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72060a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = f.split('\\n')\n",
    "\n",
    "topics = [topic.split(': ')[-1] for topic in topics if topic != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec69ca43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['древний возраст кость геном слой находка поздний след популяция днк сапиенс неандерталец зуб признак генетический',\n",
       " 'звезда масса галактика чёрный_дыра вселенная излучение солнечный космический наблюдение астроном солнце звёздный спектр ядро дыра',\n",
       " 'белок ген днк опухоль мутация мышь ткань рак участок вирус бактерия геном фермент белка рецептор',\n",
       " 'частица энергия физика ядро электрон нейтрино детектор протон измерение масса распад коллаборация событие коллайдер нейтрон',\n",
       " 'вода температура атмосфера океан период порода содержание слой кислород глубина морской углерод состав зона лёд',\n",
       " 'самец самка поведение мозг нейрон сигнал особь половой муха запах потомство отбор частота популяция различие',\n",
       " 'сверхпроводник сверхпроводимость магнитный_поле мантия температура сверхпроводящий магнитный ядро зона материал вихрь образование критический_температура плёнка поле',\n",
       " 'молекула химический реакция вода атом водород синтез свойство соединение ион материал молекулярный концентрация электрон температура',\n",
       " 'луна затмение полный фаза аппарат солнце астероид свет солнечный планета орбита наблюдение спутник высота тёмный',\n",
       " 'теория открытие наука научный физика поле профессор поздний уравнение физический эйнштейн масса история решение коллега',\n",
       " 'ген геном позвоночный тело экспрессия генетический эволюционный признак функция мышца орган конечность hox-ген насекомое крыло',\n",
       " 'эукариот губка происхождение ветвь древний предок многоклеточный_животное митохондрия личинка нервный_система общий_предок эволюционный членистоногий гребневик морской',\n",
       " 'рост быстрый вероятность информация задача слово оценка зависимость мера фактор средний целое дальнейший параметр среднее',\n",
       " 'растение птица популяция рыба хищник численность сообщество насекомое дерево лист особь разнообразие пища мелкий муравей',\n",
       " 'свет квантовый атом энергия движение частота температура волна объект сила поле излучение порядок колебание свойство']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f7e107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCENT_MAPPING = {\n",
    "    '́': '',\n",
    "    '̀': '',\n",
    "    'а́': 'а',\n",
    "    'а̀': 'а',\n",
    "    'е́': 'е',\n",
    "    'ѐ': 'е',\n",
    "    'и́': 'и',\n",
    "    'ѝ': 'и',\n",
    "    'о́': 'о',\n",
    "    'о̀': 'о',\n",
    "    'у́': 'у',\n",
    "    'у̀': 'у',\n",
    "    'ы́': 'ы',\n",
    "    'ы̀': 'ы',\n",
    "    'э́': 'э',\n",
    "    'э̀': 'э',\n",
    "    'ю́': 'ю',\n",
    "    '̀ю': 'ю',\n",
    "    'я́́': 'я',\n",
    "    'я̀': 'я',\n",
    "}\n",
    "ACCENT_MAPPING = {unicodedata.normalize('NFKC', i): j for i, j in ACCENT_MAPPING.items()}\n",
    "\n",
    "\n",
    "def unaccentify(s):\n",
    "    ## чтобы не было проблем с надстрочными символами\n",
    "    \n",
    "    source = unicodedata.normalize('NFKC', s)\n",
    "    for old, new in ACCENT_MAPPING.items():\n",
    "        source = source.replace(old, new)\n",
    "    return source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33f2602f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class googling():\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.driver = webdriver.Chrome(ChromeDriverManager().install())  ##  инициализация веб-драйвера\n",
    "        self.morph = pymorphy2.MorphAnalyzer()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _parse(self):\n",
    "        ##  внутренняя функция парсинга\n",
    "        \n",
    "        soup = bs(self.driver.page_source, 'html.parser')\n",
    "        search = soup.find_all('div', class_=\"yuRUbf\")\n",
    "        for h in search:\n",
    "            self.names.append(h.get_text())\n",
    "\n",
    "\n",
    "    \n",
    "    def find(self, word, pages=3):\n",
    "        ##  ищет первые 30 (по умолчанию) выдач; кол-во страниц можно настраивать\n",
    "        \n",
    "        \n",
    "        self.word = word\n",
    "        self.names = [] \n",
    "        url = \"http://www.google.com/search?q=\" + self.word\n",
    "        self.driver.get(url)\n",
    "        \n",
    "        self._parse()  ##  парсим\n",
    "        \n",
    "        for n in range(pages-1):\n",
    "            try:\n",
    "                ##  поиск дополнительных 20 \n",
    "                ##  смотрим страницу 2 и 3 в поисковой выдаче\n",
    "                ##  в будущем нужно выделить в отдельную функцию (если будем смотреть все 30 выдач)\n",
    "\n",
    "                action = ActionChains(self.driver)\n",
    "                action.key_down(Keys.END).perform()  ##  скролим страницу вниз\n",
    "\n",
    "\n",
    "                xpath = '//*[@id=\"pnnext\"]/span[2]'\n",
    "                element = Wait(self.driver, 10).until(EC.presence_of_element_located((By.XPATH, xpath)))\n",
    "                element.click()  ##  нажимаем на \"следующий\"\n",
    "\n",
    "                self._parse()  ##  парсим\n",
    "\n",
    "            except:\n",
    "                ##  в случае если по этим топикам нет много данных\n",
    "                pass\n",
    "        \n",
    "        self.clean()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def quit(self):\n",
    "        ##  функция выхода из веб-драйвера\n",
    "        ##  по сути дублирует функцию самого драйвера, но в ООП иначе никак\n",
    "        \n",
    "        self.driver.quit()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def _lemmatize(self, text):\n",
    "        ## лемматизация\n",
    "        return \" \".join([self.morph.parse(word)[0].normal_form for word in text.split()])\n",
    "        \n",
    "    \n",
    "    def clean(self):\n",
    "        ##  внутренняя функция, призванная очистить от лишних знаков\n",
    "        ##  надо доработать исходя из того, что требуется в итоге\n",
    "        \n",
    "        \n",
    "        self.result = []\n",
    "\n",
    "        for name in self.names:\n",
    "            text = re.split('http', name)[0]\n",
    "            text = re.sub('[-|a-z|.|,|:|0-9|A-z\"]', '', text)\n",
    "            text = re.sub('  ', ' ', text)\n",
    "            \n",
    "            self.result.append(self._lemmatize(text.strip('  ')))\n",
    "            \n",
    "\n",
    "    \n",
    "    def show_topics(self):\n",
    "        ##  для проверки результатов без сохранения в отдельный файл\n",
    "\n",
    "        print('QUERY:  ', self.word)\n",
    "        print('TITLES: \\n\\n')\n",
    "        for res in self.result:\n",
    "            print(res)\n",
    "        \n",
    "             \n",
    "            \n",
    "    def save(self, kuda):\n",
    "        ##  сохраняем результаты поисковой выдачи (ОТ ОДНОГО ТОПИКА) в отдельный файл \n",
    "        \n",
    "        source = str(kuda) + '.txt'\n",
    "        with open(source, 'w', encoding=\"utf-8\") as f:\n",
    "            f.write(f'QUERY: {self.word}\\n')\n",
    "            f.write('TITLES:\\n')\n",
    "            for res in self.result:\n",
    "                f.write(res)\n",
    "                f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5ea793b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 109.0.5414\n",
      "Get LATEST chromedriver version for 109.0.5414 google-chrome\n",
      "Driver [C:\\Users\\Марк\\.wdm\\drivers\\chromedriver\\win32\\109.0.5414.74\\chromedriver.exe] found in cache\n",
      "<ipython-input-14-570a913e7587>:4: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  self.driver = webdriver.Chrome(ChromeDriverManager().install())  ##  инициализация веб-драйвера\n"
     ]
    }
   ],
   "source": [
    "yandex_part = googling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa6ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##  смотрим топик 5\n",
    "\n",
    "\n",
    "#yandex_part.find(topics[5])\n",
    "#yandex_part.show_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3a8aee",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'topics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a64c56bc5470>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m## ищем 40 выдач для каждого топика (просматриваем 4 страницы)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopic\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0myandex_part\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0myandex_part\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'lias_topics/topic_{n}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'topics' is not defined"
     ]
    }
   ],
   "source": [
    "## смотрим все 10 топиков, записываем результат от каждого топика в отдельный файл\n",
    "## ищем 40 выдач для каждого топика (просматриваем 4 страницы)\n",
    "\n",
    "for n, topic in enumerate(topics):\n",
    "    yandex_part.find(topic, pages=4)\n",
    "    yandex_part.save(f'lias_topics/topic_{n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1b1cbf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yandex_part.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e62eb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c777c8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\conda\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\conda\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\conda\\lib\\site-packages\\numpy\\.libs\\libopenblas.GK7GX5KEQ4F6UYO3P26ULGBQYHGQO7J4.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "INFO:pymorphy2.opencorpora_dict.wrapper:Loading dictionaries from C:\\conda\\lib\\site-packages\\pymorphy2_dicts_ru\\data\n",
      "INFO:pymorphy2.opencorpora_dict.wrapper:format: 2.4, revision: 417127, updated: 2020-10-11T15:05:51.070345\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import collections\n",
    "import logging\n",
    "import re\n",
    "import pymorphy2\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "morph = pymorphy2.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6119fc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {}\n",
    "\n",
    "for n in range(0, 10):\n",
    "    with open(f'lias_topics/topic_{n}.txt', 'r', encoding='utf-8') as f:\n",
    "        titles[n] = f.read().split('\\n')[2:-1]\n",
    "        \n",
    "        ##  чтобы было без query & titles добавить [2:]\n",
    "        ##  пока без лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde08d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53aa5c06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a200c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50887bdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a6550a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968b04b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fb36a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb66bdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9a197f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddaf6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a807340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Первичная Ранжировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "911f5126",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = {}\n",
    "\n",
    "for n in range(0, 10):\n",
    "    with open(f'lias_topics/topic_{n}.txt', 'r', encoding='utf-8') as f:\n",
    "        titles[n] = f.read().split('\\n')[2:-1]\n",
    "        \n",
    "        ##  чтобы было без query & titles добавить [2:]\n",
    "        ##  пока без лемматизации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7507f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['краткий теория',\n",
       " 'сверхпроводимость википедия',\n",
       " 'московский физикотехнический институт',\n",
       " 'глава физика сверхпроводимость • в гинзбург быть',\n",
       " 'сверхпроводник',\n",
       " 'проект российский научный фонд',\n",
       " 'магнит и сверхпроводник вместе – это сила! наука и жизнь',\n",
       " 'содержание работа',\n",
       " 'сверхпроводник википедия',\n",
       " 'сверхпроводник']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles[6][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "faa79bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  сразу ранжируем все выдачи, но! для каждой выдачи по отдельности\n",
    "\n",
    "\n",
    "query_n = 10  ## the number of filenames (which contain all results from a single query)\n",
    "topics_dict = {} # {'topic': [word1, word2, ...]}\n",
    "for number in range(query_n):\n",
    "    i = 0\n",
    "    length = len(titles[number]) - 1\n",
    "    while i < length:\n",
    "        topics_dict[titles[number][i]] = titles[number][i+1].split(' ')\n",
    "        i += 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c5b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  Переранжировка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "464b9807",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "from nltk import FreqDist\n",
    "\n",
    "# ПРАВИЛО 1\n",
    "def one(topics_dict, topic):\n",
    "    for small_label in topics_dict[topic][::-1]: # идём с конца, потому что если их несколько, тогда лучшие будут в начале\n",
    "        if len(small_label.split(\" \")) == 2:\n",
    "            for big_label in topics_dict[topic]:\n",
    "                if len(big_label.split(\" \")) > 2:\n",
    "                    # приводим обе метки в нормальную форму\n",
    "                    small_label_normalized = []\n",
    "                    for a_word in small_label.split(\" \"):\n",
    "                        small_label_normalized.append(morph.parse(a_word)[0].normal_form)\n",
    "                    big_label_normalized = []\n",
    "                    for a_word in big_label.split(\" \"):\n",
    "                        big_label_normalized.append(morph.parse(a_word)[0].normal_form)\n",
    "                    if \" \".join(small_label_normalized) in \" \".join(big_label_normalized): # если маленькая в большой\n",
    "                        index_big = topics_dict[topic].index(big_label)\n",
    "                        del topics_dict[topic][index_big] # удалили длинную\n",
    "                        index_small = topics_dict[topic].index(small_label)\n",
    "                        del topics_dict[topic][index_small] # удалили короткую\n",
    "                        topics_dict[topic].insert(0, small_label) # вставили короткую в начало\n",
    "    return(topics_dict) \n",
    "\n",
    "# ПРАВИЛО 2\n",
    "# ! НЕ учитываем, что если прил-ые встретились одинаковое количество раз, нужно взять то, которое в теме стоит ближе к началу \n",
    "\n",
    "def adj_in_lables(topics_dict, topic): # возвращает словарь {прил_из_темы: сколько_раз_оно_встретилось_в_метках}\n",
    "    adj_in_topic = []\n",
    "    for topic_word in topic.split(\" \"):\n",
    "        if \"ADJF\" in morph.parse(topic_word)[0].tag: \n",
    "            adj_in_topic.append(topic_word) # получили список прилагательных в данной теме       \n",
    "    adj_from_topic_in_labels = []\n",
    "    for label in topics_dict[topic]:\n",
    "        label_normalized = []\n",
    "        words_in_label = label.split(\" \")\n",
    "        for a_word in words_in_label:\n",
    "            label_normalized.append(morph.parse(a_word)[0].normal_form)\n",
    "        for adj in adj_in_topic:\n",
    "            if adj in label_normalized:\n",
    "                adj_from_topic_in_labels.append(adj) # получили список прилагательных из темы в метках\n",
    "    freq_dist = FreqDist(adj_from_topic_in_labels) # получили их распределение\n",
    "    freq = {}\n",
    "    for item in freq_dist.most_common(len(freq_dist)):\n",
    "        freq[item[0]] = item[1]\n",
    "    return freq\n",
    "    \n",
    "def two(topics_dict, topic):\n",
    "    LOTS_OF = 5\n",
    "    # получаем словарь, сколько раз какие существительные встречаются в метках длины >= 2\n",
    "    nouns_in_big_labels = []\n",
    "    for label in topics_dict[topic]:\n",
    "        #if len(label.split(\" \")) >= 2:\n",
    "        for a_word in label.split(\" \"):\n",
    "            if \"NOUN\" in morph.parse(a_word)[0].tag:\n",
    "                nouns_in_big_labels.append(morph.parse(a_word)[0].normal_form)\n",
    "    freq_dist = FreqDist(nouns_in_big_labels)\n",
    "    freq = {}\n",
    "    for item in freq_dist.most_common(len(freq_dist)):\n",
    "        freq[item[0]] = item[1]\n",
    "    \n",
    "    # если существительное встречалолсь много раз в метках, мы удаляем все длинные метки с ним\n",
    "    for noun in list(freq.keys())[::-1]: # идём с конца: если таких сущ несколько, на первом месте будет то, которого больше всего \n",
    "        if freq[noun] >= LOTS_OF:\n",
    "            to_delete = []\n",
    "            for label in topics_dict[topic]:\n",
    "                label_normalized = []\n",
    "                for a_word in label.split(\" \"):\n",
    "                    label_normalized.append(morph.parse(a_word)[0].normal_form)\n",
    "                if noun in \" \".join(label_normalized): # нашли метку, в которой это слово\n",
    "                    to_delete.append(label) # собираем список меток, которые нужно будет удалить\n",
    "            \n",
    "            for bad_label in to_delete:\n",
    "                index = topics_dict[topic].index(bad_label)\n",
    "                del topics_dict[topic][index] # удаляем их\n",
    "                    \n",
    "            # теперь, когда удалили, мы проверяем, встречаются ли в метках прилагательные из темы\n",
    "            adj_from_topics_in_labels = adj_in_lables(topics_dict, topic)\n",
    "            \n",
    "            if len(adj_from_topics_in_labels) > 0: # если да: добавляем к нашему сущ самое частое прил и ставим на первое место\n",
    "                for key in adj_from_topics_in_labels:\n",
    "                    adj = key\n",
    "                    break\n",
    "                gender = morph.parse(noun)[0].tag.gender \n",
    "                if gender == 'masc':\n",
    "                    right_adj = morph.parse(adj)[0].lexeme[0].word\n",
    "                if gender == 'femn':\n",
    "                    right_adj = morph.parse(adj)[0].lexeme[7].word\n",
    "                if gender == 'neut':\n",
    "                    right_adj = morph.parse(adj)[0].lexeme[14].word\n",
    "                new_label = right_adj + \" \" + noun\n",
    "                topics_dict[topic].insert(0, new_label)                \n",
    "                \n",
    "            else: # если нет, ставим существительное во мн.ч. и на первое место\n",
    "                try:\n",
    "                    noun_pl = morph.parse(noun)[0].lexeme[6].word\n",
    "                    topics_dict[topic].insert(0, noun_pl)\n",
    "                except IndexError: # нет мн ч - оставляем в единственном, приводим к словарной форме\n",
    "                    topics_dict[topic].insert(0, morph.parse(a_word)[0].normal_form)\n",
    "    return(topics_dict)\n",
    "\n",
    "# ПРАВИЛО 3\n",
    "def three(topics_dict, topic):\n",
    "    to_move = [] # a list with pairs (label_to_be_moved, its_index)\n",
    "    for label in topics_dict[topic]:\n",
    "        if len(label.split(\" \")) > 2:\n",
    "            index = topics_dict[topic].index(label)\n",
    "            to_move.append((label, index)) \n",
    "    for pair in to_move:\n",
    "        new_index = topics_dict[topic].index(pair[0])\n",
    "        del topics_dict[topic][new_index] # удалили все необходимые\n",
    "    for pair in to_move:\n",
    "        # вставляем их на две позиции позже, чем они были\n",
    "        try:\n",
    "            topics_dict[topic].insert(pair[1] + 2, pair[0])\n",
    "        except IndexError:\n",
    "            topics_dict[topic].insert(len(topics_dict[topic]), pair[0])\n",
    "    return(topics_dict)\n",
    "\n",
    "# ПРАВИЛО 4\n",
    "def four(topics_dict, topic):\n",
    "    # идём от последнего слова в теме к первому, так на первых позициях окажутся метки с более весомыми прилагательными\n",
    "    for topic_word in topic.split(\" \")[::-1]:\n",
    "        if \"ADJF\" in morph.parse(topic_word)[0].tag: # если слово в теме - прилагательное\n",
    "            for label in topics_dict[topic][::-1]: # идём от последней метки к первой - так лучшие метки окажутся сначала\n",
    "                if len(label.split(\" \")) > 1:\n",
    "                    label_normalized = []\n",
    "                    words_in_label = label.split(\" \")\n",
    "                    for a_word in words_in_label:\n",
    "                        label_normalized.append(morph.parse(a_word)[0].normal_form)\n",
    "                    if topic_word in label_normalized: # если оно же встретилось в (лемматизированной) метке\n",
    "                        index = topics_dict[topic].index(label)\n",
    "                        del topics_dict[topic][index] # удаляем эту метку с её позиции\n",
    "                        topics_dict[topic].insert(0, \" \".join(label_normalized)) # вставляем её в самое начало\n",
    "                        #### !!!!! ####\n",
    "    return topics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8697ceb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rules(topics_dict, topic):\n",
    "    four(topics_dict, topic)\n",
    "    three(topics_dict, topic)\n",
    "    two(topics_dict, topic)\n",
    "    one(topics_dict, topic)\n",
    "    return(topics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc0f02df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "неандерталец википедия\n",
      "древний днк европа средний палеолит (неандертальцы)\n",
      "() человек разумный и всевсевсе пособие\n",
      "база информационный потребность\n",
      "человек из денисов пещера оказаться не сапиенс и\n",
      "неандерталец\n",
      "кроманьонец википедия\n",
      "секвенировать геном неандерталец из чагырский пещера\n",
      "неандерталец такой же человек как мы просто они не\n",
      "тот в с мосина южный урал в каменный век\n",
      "генетика завершить работа антрополог над сам\n",
      "генетический след ведущий к\n",
      "чёрный дыра википедия\n",
      "словарь термин\n",
      "астрономия\n",
      "рпастрономия класс мбоу сош №\n",
      "сверхмассивный чёрный дыра википедия\n",
      "млечный путь википедия\n",
      "астрономия контрольный и самостоятельный работа\n",
      "рабочий учебный программа по астрономия для класс\n",
      "рабочий программа учебный курс по астрономия для\n",
      "программа астрономия рушинскай школа №\n",
      "класс рабочий программа астрономия\n",
      "внеатмосферный астрономия\n",
      "строение и эволюция вселенная\n",
      "проект\n",
      "астрономия базовый уровень класс» учебный главный\n",
      "о возможность существование чёрный дыра в рамка\n",
      "астрономия класс (вм чаругин)\n",
      "метод в картинка генный инженерия часть\n",
      "тестовый задание\n",
      "медицинский генетика\n",
      "проект российский научный фонд\n",
      "медицинский биология и общий генетика\n",
      "клеточный и молекулярный основа опухолевый рост\n",
      "вирусология\n",
      "федеральный государственный бюджетный научный\n",
      "онкогенетик и эпигенетик\n",
      "медицинский генетика для студент факультет всо\n",
      "нобелевский лауреат рассказать как из обычный клетка\n",
      "молекулярногенетический особенность мышечный\n",
      "тезис\n",
      "франккаменецкий самый главный молекула\n",
      "элементарный частица\n",
      "введение в физика нейтрино\n",
      "эксперимент ядерный физика в интернет\n",
      "физика опровергнуть наличие двойник у бозон хиггс\n",
      "физика элементарный частица ияи ран\n",
      "надежда на странный тасс\n",
      "удк в и телён ияф с ран\n",
      "внглазков «атомный и ядерный физика»\n",
      "перед старт в микрокосм коллайдер готовиться к запуск\n",
      "федеральный государственный бюджетный учреждение\n",
      "нейтринный излучение ассоциация победитель олимпиада\n",
      "о продвижение к новый физика среди самый важный\n",
      "чармоний в распад прелестный частица в эксперимент\n",
      "пияф в\n",
      "океан (мировой океан)\n",
      "физика природный среды» часть «мировой океан»\n",
      "геохимия биосфера\n",
      "гидросфера земля электронный учебник\n",
      "земля википедия\n",
      "история земля википедия\n",
      "учение о гидросфера научный библиотека ярг\n",
      "открывать тайна океан главный\n",
      "содержание\n",
      "тихий океан • больший российский энциклопедия\n",
      "десятилетие наука о океан оон\n",
      "экология как наука\n",
      "геология море и океан\n",
      "определение состав и строение осадочный порода\n",
      "ненаследуемый особенность строение мозг определить\n",
      "физиология высокий нервный деятельность и сенсорный\n",
      "биология в кнкнярыгин учебник\n",
      "часть первый вводный сведение\n",
      "ибр ран / новость биология развитие\n",
      "эгоистичный ген\n",
      "биология (учебник) м вунмц с\n",
      "нейрон википедия\n",
      "как зажечь мозг\n",
      "краткий теория\n",
      "московский физикотехнический институт\n",
      "сверхпроводник\n",
      "магнит и сверхпроводник вместе – это сила! наука и жизнь\n",
      "сверхпроводник википедия\n",
      "сверхпроводимость википедия\n",
      "водород википедия\n",
      "химия\n",
      "основной представление о химия\n",
      "водород он физический и химический свойство фоксфорд\n",
      "введение\n",
      "методический рекомендация к изучение тем курс химия\n",
      "основа общий и неорганический химия\n",
      "химический реакция полимер\n",
      "органический химия\n",
      "задача московский астрономический олимпиада\n",
      "как располагаться солнце земля и луна в\n",
      "ответ астроном на вопрос большой новосибирский\n",
      "задача санктпетербургский астрономический\n",
      "учебный пособие\n",
      "солнечный система электронный библиотека рггма\n",
      "история астрономия в задача\n",
      "министерство образование и наука российский федерация\n",
      "баворонцоввельямин ек страут моу сош №\n",
      "общий астрономия часть\n",
      "исследование космос космический лента\n",
      "астрономия национальный институт образование\n",
      "ответ к билет по астрономия астрономия в школа\n",
      "муртазовый ак «англорусский астрономический словарь\n",
      "альберт эйнштейн и «теория весь троицкий вариант\n",
      "эйнштейн альберт википедия\n",
      "можно ли считать поздний эйнштейн неудачником?\n",
      "липкина аи &;основание современный мфть\n",
      "история и методология физика\n",
      "теория относительность википедия\n",
      "список научный публикация альберт эйнштейн википедия\n",
      "альберт эйнштейн и он уникальный наследие\n",
      "упрямый иллюзия или физический реальность? что наука\n",
      "эйнштейн жизнь смерть бессмертие изд быть перераб\n",
      "физика шутить\n",
      "между технический библиотека\n",
      "играть ли кот в кости? эйнштейн и шрёдингер в поиск\n",
      "вя френкель бе явеловый эйнштейн изобретение\n",
      "книга «юрий борисович румереть физика век\n"
     ]
    }
   ],
   "source": [
    "for topic in topics_dict:\n",
    "    print(topic)\n",
    "    apply_rules(topics_dict, topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3e4262e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "неандерталец википедия ---- днк\n",
      "древний днк европа средний палеолит (неандертальцы) ---- цивилизация\n",
      "() человек разумный и всевсевсе пособие ---- неандерталец\n",
      "база информационный потребность ---- –\n",
      "человек из денисов пещера оказаться не сапиенс и ---- ктоть\n",
      "неандерталец ---- эпигенетический\n",
      "кроманьонец википедия ---- неандерталец\n",
      "секвенировать геном неандерталец из чагырский пещера ---- неандерталец\n",
      "неандерталец такой же человек как мы просто они не ---- (неандерталец)\n",
      "тот в с мосина южный урал в каменный век ---- чеплыгин\n",
      "генетика завершить работа антрополог над сам ---- эволюция\n",
      "генетический след ведущий к ---- год\n",
      "чёрный дыра википедия ---- галактический\n",
      "словарь термин ---- космический\n",
      "астрономия ---- спектррг\n",
      "рпастрономия класс мбоу сош № ---- многоканальный\n",
      "сверхмассивный чёрный дыра википедия ---- астроном\n",
      "млечный путь википедия ---- галактический\n",
      "астрономия контрольный и самостоятельный работа ---- общий\n",
      "рабочий учебный программа по астрономия для класс ---- астрономиякласс\n",
      "рабочий программа учебный курс по астрономия для ---- как\n",
      "программа астрономия рушинскай школа № ---- пояснительный\n",
      "класс рабочий программа астрономия ---- академия\n",
      "внеатмосферный астрономия ---- \n",
      "строение и эволюция вселенная ---- откуда\n",
      "проект ---- задача\n",
      "астрономия базовый уровень класс» учебный главный ---- рабочий\n",
      "о возможность существование чёрный дыра в рамка ---- астрономия\n",
      "астрономия класс (вм чаругин) ---- \n",
      "метод в картинка генный инженерия часть ---- курс\n",
      "тестовый задание ---- тезис\n",
      "медицинский генетика ---- клеточный\n",
      "проект российский научный фонд ---- ген\n",
      "медицинский биология и общий генетика ---- эволюционный\n",
      "клеточный и молекулярный основа опухолевый рост ---- генетический\n",
      "вирусология ---- молекулярный\n",
      "федеральный государственный бюджетный научный ---- –\n",
      "онкогенетик и эпигенетик ---- биология\n",
      "медицинский генетика для студент факультет всо ---- биологический\n",
      "нобелевский лауреат рассказать как из обычный клетка ---- успех\n",
      "молекулярногенетический особенность мышечный ---- научный\n",
      "тезис ---- библиотека\n",
      "франккаменецкий самый главный молекула ---- геномик\n",
      "элементарный частица ---- физика\n",
      "введение в физика нейтрино ---- лаборатория\n",
      "эксперимент ядерный физика в интернет ---- ядерный\n",
      "физика опровергнуть наличие двойник у бозон хиггс ---- протон\n",
      "физика элементарный частица ияи ран ---- кирпичик\n",
      "надежда на странный тасс ---- величина\n",
      "удк в и телён ияф с ран ---- \n",
      "внглазков «атомный и ядерный физика» ---- открытие\n",
      "перед старт в микрокосм коллайдер готовиться к запуск ---- эксперимент\n",
      "федеральный государственный бюджетный учреждение ---- тезис\n",
      "нейтринный излучение ассоциация победитель олимпиада ---- физика\n",
      "о продвижение к новый физика среди самый важный ---- лекция\n",
      "чармоний в распад прелестный частица в эксперимент ---- физика\n",
      "пияф в ---- современный\n",
      "океан (мировой океан) ---- химия\n",
      "физика природный среды» часть «мировой океан» ---- предисловие\n",
      "геохимия биосфера ---- простой\n",
      "гидросфера земля электронный учебник ---- физический\n",
      "земля википедия ---- краткий\n",
      "история земля википедия ---- михайлов\n",
      "учение о гидросфера научный библиотека ярг ---- программа\n",
      "открывать тайна океан главный ---- рб\n",
      "содержание ---- океан\n",
      "тихий океан • больший российский энциклопедия ---- океан\n",
      "десятилетие наука о океан оон ---- гидрохимия\n",
      "экология как наука ---- основа\n",
      "геология море и океан ---- заявление\n",
      "определение состав и строение осадочный порода ---- \n",
      "ненаследуемый особенность строение мозг определить ---- обзор\n",
      "физиология высокий нервный деятельность и сенсорный ---- мозг\n",
      "биология в кнкнярыгин учебник ---- энтомология\n",
      "часть первый вводный сведение ---- биология\n",
      "ибр ран / новость биология развитие ---- определить\n",
      "эгоистичный ген ---- бурлак\n",
      "биология (учебник) м вунмц с ---- нейробиология\n",
      "нейрон википедия ---- как\n",
      "как зажечь мозг ---- учёный\n",
      "краткий теория ---- сверхпроводимость\n",
      "московский физикотехнический институт ---- глава\n",
      "сверхпроводник ---- проект\n",
      "магнит и сверхпроводник вместе – это сила! наука и жизнь ---- содержание\n",
      "сверхпроводник википедия ---- сверхпроводник\n",
      "сверхпроводимость википедия ---- магнит\n",
      "водород википедия ---- глава\n",
      "химия ---- химия\n",
      "основной представление о химия ---- водород\n",
      "водород он физический и химический свойство фоксфорд ---- глава\n",
      "введение ---- водород\n",
      "методический рекомендация к изучение тем курс химия ---- химия\n",
      "основа общий и неорганический химия ---- химия\n",
      "химический реакция полимер ---- лекция\n",
      "органический химия ---- химия\n",
      "задача московский астрономический олимпиада ---- всероссийский\n",
      "как располагаться солнце земля и луна в ---- когда\n",
      "ответ астроном на вопрос большой новосибирский ---- приоритет\n",
      "задача санктпетербургский астрономический ---- занимательный\n",
      "учебный пособие ---- учебник\n",
      "солнечный система электронный библиотека рггма ---- справочник\n",
      "история астрономия в задача ---- август\n",
      "министерство образование и наука российский федерация ---- репозиторий\n",
      "баворонцоввельямин ек страут моу сош № ---- астрономия\n",
      "общий астрономия часть ---- современный\n",
      "исследование космос космический лента ---- реферат\n",
      "астрономия национальный институт образование ---- астрономия\n",
      "ответ к билет по астрономия астрономия в школа ---- что\n",
      "муртазовый ак «англорусский астрономический словарь ---- планета\n",
      "альберт эйнштейн и «теория весь троицкий вариант ---- общий\n",
      "эйнштейн альберт википедия ---- системноинтегративный\n",
      "можно ли считать поздний эйнштейн неудачником? ---- посвящаться\n",
      "липкина аи &;основание современный мфть ---- тонкий\n",
      "история и методология физика ---- г\n",
      "теория относительность википедия ---- теория\n",
      "список научный публикация альберт эйнштейн википедия ---- эйнштейн\n",
      "альберт эйнштейн и он уникальный наследие ---- трагедия\n",
      "упрямый иллюзия или физический реальность? что наука ---- трушин\n",
      "эйнштейн жизнь смерть бессмертие изд быть перераб ---- трагедия\n",
      "физика шутить ---- эйнштейн\n",
      "между технический библиотека ---- из\n",
      "играть ли кот в кости? эйнштейн и шрёдингер в поиск ---- история\n",
      "вя френкель бе явеловый эйнштейн изобретение ---- альберт\n",
      "книга «юрий борисович румереть физика век ---- эйнштейн\n"
     ]
    }
   ],
   "source": [
    "for topic in topics_dict:\n",
    "    print(topic + ' ---- ' + topics_dict[topic][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5312c81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "path = \"lias_topics/GLDA_googled_Lyasdata10.txt\"\n",
    "first_n = 10\n",
    "with codecs.open(path, 'w', 'utf8') as output_file:\n",
    "    for topic in topics_dict:\n",
    "        output_file.write('TOPIC:' + \", \".join(topics_dict[topic][:1]) + '\\n')\n",
    "        output_file.write('LABELS:  ' + topic + '\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
